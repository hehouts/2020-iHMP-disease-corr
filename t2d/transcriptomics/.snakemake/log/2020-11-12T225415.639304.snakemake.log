Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	all
	1140	download_data
	1141

[Thu Nov 12 22:54:18 2020]
rule download_data:
    output: raw_data/zipped_data/SCGPM_WZ09-P4_CAW2F_L4_TCCGGAGA_R2.tar
    jobid: 1030
    wildcards: sample=SCGPM_WZ09-P4_CAW2F_L4_TCCGGAGA_R2

Terminating processes on user request, this might take some time.
[Thu Nov 12 22:54:46 2020]
Error in rule download_data:
    jobid: 1030
    output: raw_data/zipped_data/SCGPM_WZ09-P4_CAW2F_L4_TCCGGAGA_R2.tar
    shell:
        wget -O raw_data/zipped_data/SCGPM_WZ09-P4_CAW2F_L4_TCCGGAGA_R2.tar http://downloads.hmpdacc.org/ihmp/t2d/transcriptome/host/raw/SCGPM_WZ09-P4_CAW2F_L4_TCCGGAGA_R2.fastq.gz
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Removing output files of failed job download_data since they might be corrupted:
raw_data/zipped_data/SCGPM_WZ09-P4_CAW2F_L4_TCCGGAGA_R2.tar
Complete log: /home/hehouts/2020-iHMP-T2D/transcriptomics/.snakemake/log/2020-11-12T225415.639304.snakemake.log
